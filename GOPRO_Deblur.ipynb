{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%nvidia-smi` not found.\n"
     ]
    }
   ],
   "source": [
    "%nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 294,
     "status": "ok",
     "timestamp": 1669621598971,
     "user": {
      "displayName": "서성종",
      "userId": "04139841364071843075"
     },
     "user_tz": -540
    },
    "id": "2y1qh_BeB1Xt"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import os\n",
    "from PIL import Image\n",
    "import time\n",
    "from skimage.metrics import peak_signal_noise_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 504,
     "status": "ok",
     "timestamp": 1669621601281,
     "user": {
      "displayName": "서성종",
      "userId": "04139841364071843075"
     },
     "user_tz": -540
    },
    "id": "-Y_GkAhhB_nI",
    "outputId": "6152ccf6-3ea9-4e5d-bdc4-953b9681d892"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0 is available.\n"
     ]
    }
   ],
   "source": [
    "# CPU/GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'{device} is available.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 291,
     "status": "ok",
     "timestamp": 1669621604936,
     "user": {
      "displayName": "서성종",
      "userId": "04139841364071843075"
     },
     "user_tz": -540
    },
    "id": "MtU9fL90R51C"
   },
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, image_dir, transform=None, test=False):\n",
    "        self.image_dir = image_dir\n",
    "        self.image_list = os.listdir(os.path.join(image_dir, 'blur/'))\n",
    "        self.image_list.sort()\n",
    "        self.transform = transform\n",
    "        self.test = test\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(os.path.join(self.image_dir, 'blur', self.image_list[idx]))\n",
    "        label = Image.open(os.path.join(self.image_dir, 'sharp', self.image_list[idx]))\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            label = self.transform(label)\n",
    "        else:\n",
    "            tf_toTensor = transforms.ToTensor()\n",
    "            image = tf_toTensor(image)\n",
    "            label = tf_toTensor(label)\n",
    "        if self.test:\n",
    "            name = self.image_list[idx]\n",
    "            return image, label, name\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 254,
     "status": "ok",
     "timestamp": 1669621611177,
     "user": {
      "displayName": "서성종",
      "userId": "04139841364071843075"
     },
     "user_tz": -540
    },
    "id": "4m3FKnEVpEXG"
   },
   "outputs": [],
   "source": [
    "def train_dataloader(path, batch_size = 64, num_workers=0):\n",
    "    image_dir = os.path.join(path, 'train')\n",
    "\n",
    "    transform = transforms.Compose(\n",
    "        \n",
    "        [transforms.Resize((256, 256)),\n",
    "         transforms.RandomCrop(224),\n",
    "         transforms.RandomHorizontalFlip(),\n",
    "         transforms.ToTensor(),\n",
    "         ]\n",
    "     )\n",
    "  \n",
    "    dataloader = DataLoader(\n",
    "        MyDataset(image_dir, transform=transform),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers\n",
    "        )\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 270,
     "status": "ok",
     "timestamp": 1669617926075,
     "user": {
      "displayName": "서성종",
      "userId": "04139841364071843075"
     },
     "user_tz": -540
    },
    "id": "3hCDDVZjqrTi"
   },
   "outputs": [],
   "source": [
    "def test_dataloader(path, batch_size = 1, num_workers=0):\n",
    "    image_dir = os.path.join(path, 'test')\n",
    "  \n",
    "    dataloader = DataLoader(\n",
    "        MyDataset(image_dir, test=True),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers\n",
    "        )\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 236,
     "status": "ok",
     "timestamp": 1669621631714,
     "user": {
      "displayName": "서성종",
      "userId": "04139841364071843075"
     },
     "user_tz": -540
    },
    "id": "Ytkpc1er6SdP"
   },
   "outputs": [],
   "source": [
    "path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 262,
     "status": "ok",
     "timestamp": 1669621643052,
     "user": {
      "displayName": "서성종",
      "userId": "04139841364071843075"
     },
     "user_tz": -540
    },
    "id": "9VZLOHFNshS9"
   },
   "outputs": [],
   "source": [
    "def _train(model, max_epoch = 10, lr = 0.002, resume=False):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    criterion = torch.nn.L1Loss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr, weight_decay=0)\n",
    "    dataloader = train_dataloader(path, batch_size=32, num_workers=0)\n",
    "    writer = SummaryWriter('logs/')\n",
    "\n",
    "    epoch = 1\n",
    "\n",
    "    if (resume == True):\n",
    "        PATH = 'weights/weights0.002v3.pth'\n",
    "        checkpoint = torch.load(PATH)\n",
    "        net.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        epoch = checkpoint['epoch']\n",
    "        loss = checkpoint['loss']\n",
    "        epoch += 1\n",
    "    print('Starting from Epoch :',epoch)\n",
    "\n",
    "    since = time.time()\n",
    "    for epoch_idx in range(epoch, max_epoch+1):\n",
    "        running_loss = 0.0\n",
    "        cnt = 0\n",
    "        epoch_time = time.time()\n",
    "        for idx, batch in enumerate(dataloader):\n",
    "            optimizer.zero_grad()\n",
    "            input, target = batch\n",
    "            input = input.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            output = net(input)\n",
    "            loss = criterion(output, target)\n",
    "            writer.add_scalar(\"Loss/train\", loss, epoch_idx)\n",
    "                \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "  \n",
    "            running_loss += loss.item()\n",
    "            cnt += 1\n",
    "\n",
    "        if (epoch_idx % 10 == 1):\n",
    "            time_elapsed = time.time() - epoch_time\n",
    "            total_time = time.time() - since\n",
    "            print('Training complete in {:.0f}m {:.0f}s, Total time : {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60, total_time // 60, total_time % 60))\n",
    "            print(f'Epoch: {epoch_idx}, Loss: {running_loss / cnt:.3f}saved')\n",
    "      \n",
    "        PATH = 'weights/weights0.002v3.pth'\n",
    "        torch.save({\n",
    "                'epoch': epoch_idx,\n",
    "                'model_state_dict': net.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': loss,\n",
    "                \n",
    "                  }, PATH)\n",
    "    writer.flush()\n",
    "    writer.close()\n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 247,
     "status": "ok",
     "timestamp": 1669621651035,
     "user": {
      "displayName": "서성종",
      "userId": "04139841364071843075"
     },
     "user_tz": -540
    },
    "id": "QCqDAfpvN5lX"
   },
   "outputs": [],
   "source": [
    "def _test(model):\n",
    "    PATH = 'weights/weights0.002v3.pth'\n",
    "    checkpoint = torch.load(PATH)\n",
    "    net.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    dataloader = test_dataloader(path, batch_size=1, num_workers=0)\n",
    "    torch.cuda.empty_cache()\n",
    "    total_psnr = 0.0\n",
    "    cnt = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for iter_idx, data in enumerate(dataloader):\n",
    "\n",
    "            input_img, label_img, name = data\n",
    "            input_img = input_img.to(device)\n",
    "            pred = net(input_img)\n",
    "\n",
    "            pred_clip = torch.clamp(pred, 0, 1)\n",
    "    \n",
    "            pred_numpy = pred_clip.squeeze(0).cpu().numpy()\n",
    "            label_numpy = label_img.squeeze(0).cpu().numpy()\n",
    "            psnr = peak_signal_noise_ratio(pred_numpy, label_numpy, data_range=1)\n",
    "            total_psnr += psnr\n",
    "            cnt += 1\n",
    "            \n",
    "            if (iter_idx % 100 == 1):\n",
    "                print(iter_idx)\n",
    "                plt.imshow(np.transpose(pred_numpy, (1,2,0)))\n",
    "                plt.show()\n",
    "                plt.imshow(np.transpose(label_numpy, (1,2,0)))\n",
    "                plt.show()\n",
    "                print('%d iter PSNR: %.2f' % (iter_idx + 1, psnr))\n",
    "            \n",
    "        print('==========================================================')\n",
    "        print('The average PSNR is %.2f dB' % (total_psnr / cnt))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 261,
     "status": "ok",
     "timestamp": 1669621658871,
     "user": {
      "displayName": "서성종",
      "userId": "04139841364071843075"
     },
     "user_tz": -540
    },
    "id": "OE1GEY4zz9iE"
   },
   "outputs": [],
   "source": [
    "class my_module3(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channel, out_channel, 3, 1, 1)\n",
    "        self.conv2 = nn.Conv2d(out_channel, out_channel, 3, 1, 1)\n",
    "        self.bn = nn.BatchNorm2d(out_channel)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.iden = nn.Conv2d(in_channel, out_channel, 1, 1, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = self.iden(x)\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn(out)\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        out = self.pool(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 261,
     "status": "ok",
     "timestamp": 1669621660264,
     "user": {
      "displayName": "서성종",
      "userId": "04139841364071843075"
     },
     "user_tz": -540
    },
    "id": "VIMmlGN03ceg"
   },
   "outputs": [],
   "source": [
    "class my_module5(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channel, out_channel, 5, 1, 2)\n",
    "        self.conv2 = nn.Conv2d(out_channel, out_channel, 5, 1, 2)\n",
    "        self.bn = nn.BatchNorm2d(out_channel)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.iden = nn.Conv2d(in_channel, out_channel, 1, 1, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = self.iden(x)\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn(out)\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 387,
     "status": "ok",
     "timestamp": 1669621662938,
     "user": {
      "displayName": "서성종",
      "userId": "04139841364071843075"
     },
     "user_tz": -540
    },
    "id": "XYvT8r3pHPDW"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = my_module3(3,32) #112*112\n",
    "        self.layer2 = my_module3(32,64) #56*56\n",
    "        self.layer3 = my_module5(64,128) #56*56\n",
    "        self.convT1 = nn.ConvTranspose2d(128,64,2,2,0) #112*112\n",
    "        self.convT2 = nn.ConvTranspose2d(64,32,2,2,0) #224*224\n",
    "        self.conv = nn.Conv2d(32, 3, 1, 1, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = F.relu(self.convT1(out))\n",
    "        out = F.relu(self.convT2(out))\n",
    "        out = self.conv(out)\n",
    "        output = out + x\n",
    "   \n",
    "        return output\n",
    "\n",
    "net = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1669616460448,
     "user": {
      "displayName": "서성종",
      "userId": "04139841364071843075"
     },
     "user_tz": -540
    },
    "id": "jFqtGoytd0JM",
    "outputId": "ad3d6a14-9b3a-4e2e-e14f-b890775bb831"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (layer1): my_module3(\n",
      "    (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU()\n",
      "    (dropout): Dropout(p=0.3, inplace=False)\n",
      "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (iden): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (layer2): my_module3(\n",
      "    (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU()\n",
      "    (dropout): Dropout(p=0.3, inplace=False)\n",
      "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (iden): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (layer3): my_module5(\n",
      "    (conv1): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU()\n",
      "    (dropout): Dropout(p=0.3, inplace=False)\n",
      "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (iden): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (convT1): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (convT2): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (conv): Conv2d(32, 3, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eHhFuxZS5rde",
    "outputId": "606645b2-6c39-4ee3-e5ee-3530f98bc745"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting from Epoch : 1\n",
      "Training complete in 3m 8s, Total time : 3m 8s\n",
      "Epoch: 1, Loss: 0.168saved\n",
      "Training complete in 2m 46s, Total time : 31m 6s\n",
      "Epoch: 11, Loss: 0.162saved\n",
      "Training complete in 3m 3s, Total time : 59m 26s\n",
      "Epoch: 21, Loss: 0.161saved\n",
      "Training complete in 2m 49s, Total time : 87m 36s\n",
      "Epoch: 31, Loss: 0.161saved\n",
      "Training complete in 2m 55s, Total time : 115m 30s\n",
      "Epoch: 41, Loss: 0.160saved\n",
      "Training complete in 2m 44s, Total time : 143m 35s\n",
      "Epoch: 51, Loss: 0.159saved\n",
      "Training complete in 2m 47s, Total time : 171m 8s\n",
      "Epoch: 61, Loss: 0.159saved\n",
      "Training complete in 2m 46s, Total time : 199m 24s\n",
      "Epoch: 71, Loss: 0.160saved\n",
      "Training complete in 2m 45s, Total time : 227m 13s\n",
      "Epoch: 81, Loss: 0.157saved\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m _train(net, max_epoch \u001b[39m=\u001b[39;49m \u001b[39m1000\u001b[39;49m, lr \u001b[39m=\u001b[39;49m \u001b[39m0.002\u001b[39;49m, resume\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "Cell \u001b[1;32mIn[16], line 24\u001b[0m, in \u001b[0;36m_train\u001b[1;34m(model, max_epoch, lr, resume)\u001b[0m\n\u001b[0;32m     22\u001b[0m cnt \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     23\u001b[0m epoch_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m---> 24\u001b[0m \u001b[39mfor\u001b[39;00m idx, batch \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(dataloader):\n\u001b[0;32m     25\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     26\u001b[0m     \u001b[39minput\u001b[39m, target \u001b[39m=\u001b[39m batch\n",
      "File \u001b[1;32mc:\\USERS\\A00559023\\ONEDRIVE - ONEVIRTUALOFFICE\\ETC\\GOPRO\\GOPRO\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:435\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    434\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[1;32m--> 435\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    436\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    437\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    438\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    439\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\USERS\\A00559023\\ONEDRIVE - ONEVIRTUALOFFICE\\ETC\\GOPRO\\GOPRO\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:475\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    474\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 475\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    476\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    477\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data)\n",
      "File \u001b[1;32mc:\\USERS\\A00559023\\ONEDRIVE - ONEVIRTUALOFFICE\\ETC\\GOPRO\\GOPRO\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:44\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     43\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[1;32m---> 44\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     45\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     46\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\USERS\\A00559023\\ONEDRIVE - ONEVIRTUALOFFICE\\ETC\\GOPRO\\GOPRO\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:44\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     43\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[1;32m---> 44\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     45\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     46\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[4], line 17\u001b[0m, in \u001b[0;36mMyDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     14\u001b[0m label \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mopen(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimage_dir, \u001b[39m'\u001b[39m\u001b[39msharp\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimage_list[idx]))\n\u001b[0;32m     16\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform:\n\u001b[1;32m---> 17\u001b[0m     image \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(image)\n\u001b[0;32m     18\u001b[0m     label \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform(label)\n\u001b[0;32m     19\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\USERS\\A00559023\\ONEDRIVE - ONEVIRTUALOFFICE\\ETC\\GOPRO\\GOPRO\\lib\\site-packages\\torchvision\\transforms\\transforms.py:67\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, img):\n\u001b[0;32m     66\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[1;32m---> 67\u001b[0m         img \u001b[39m=\u001b[39m t(img)\n\u001b[0;32m     68\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n",
      "File \u001b[1;32mc:\\USERS\\A00559023\\ONEDRIVE - ONEVIRTUALOFFICE\\ETC\\GOPRO\\GOPRO\\lib\\site-packages\\torch\\nn\\modules\\module.py:727\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slow_forward(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    726\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 727\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    728\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m itertools\u001b[39m.\u001b[39mchain(\n\u001b[0;32m    729\u001b[0m         _global_forward_hooks\u001b[39m.\u001b[39mvalues(),\n\u001b[0;32m    730\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[0;32m    731\u001b[0m     hook_result \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, result)\n",
      "File \u001b[1;32mc:\\USERS\\A00559023\\ONEDRIVE - ONEVIRTUALOFFICE\\ETC\\GOPRO\\GOPRO\\lib\\site-packages\\torchvision\\transforms\\transforms.py:267\u001b[0m, in \u001b[0;36mResize.forward\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, img):\n\u001b[0;32m    260\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    261\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m    262\u001b[0m \u001b[39m        img (PIL Image or Tensor): Image to be scaled.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[39m        PIL Image or Tensor: Rescaled image.\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mresize(img, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msize, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minterpolation)\n",
      "File \u001b[1;32mc:\\USERS\\A00559023\\ONEDRIVE - ONEVIRTUALOFFICE\\ETC\\GOPRO\\GOPRO\\lib\\site-packages\\torchvision\\transforms\\functional.py:310\u001b[0m, in \u001b[0;36mresize\u001b[1;34m(img, size, interpolation)\u001b[0m\n\u001b[0;32m    289\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Resize the input image to the given size.\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[39mThe image can be a PIL Image or a torch Tensor, in which case it is expected\u001b[39;00m\n\u001b[0;32m    291\u001b[0m \u001b[39mto have [..., H, W] shape, where ... means an arbitrary number of leading dimensions\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[39m    PIL Image or Tensor: Resized image.\u001b[39;00m\n\u001b[0;32m    308\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(img, torch\u001b[39m.\u001b[39mTensor):\n\u001b[1;32m--> 310\u001b[0m     \u001b[39mreturn\u001b[39;00m F_pil\u001b[39m.\u001b[39;49mresize(img, size\u001b[39m=\u001b[39;49msize, interpolation\u001b[39m=\u001b[39;49minterpolation)\n\u001b[0;32m    312\u001b[0m \u001b[39mreturn\u001b[39;00m F_t\u001b[39m.\u001b[39mresize(img, size\u001b[39m=\u001b[39msize, interpolation\u001b[39m=\u001b[39minterpolation)\n",
      "File \u001b[1;32mc:\\USERS\\A00559023\\ONEDRIVE - ONEVIRTUALOFFICE\\ETC\\GOPRO\\GOPRO\\lib\\site-packages\\torchvision\\transforms\\functional_pil.py:429\u001b[0m, in \u001b[0;36mresize\u001b[1;34m(img, size, interpolation)\u001b[0m\n\u001b[0;32m    427\u001b[0m         \u001b[39mreturn\u001b[39;00m img\u001b[39m.\u001b[39mresize((ow, oh), interpolation)\n\u001b[0;32m    428\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 429\u001b[0m     \u001b[39mreturn\u001b[39;00m img\u001b[39m.\u001b[39;49mresize(size[::\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m], interpolation)\n",
      "File \u001b[1;32mc:\\USERS\\A00559023\\ONEDRIVE - ONEVIRTUALOFFICE\\ETC\\GOPRO\\GOPRO\\lib\\site-packages\\PIL\\Image.py:2156\u001b[0m, in \u001b[0;36mImage.resize\u001b[1;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[0;32m   2152\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[0;32m   2154\u001b[0m size \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(size)\n\u001b[1;32m-> 2156\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload()\n\u001b[0;32m   2157\u001b[0m \u001b[39mif\u001b[39;00m box \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   2158\u001b[0m     box \u001b[39m=\u001b[39m (\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msize\n",
      "File \u001b[1;32mc:\\USERS\\A00559023\\ONEDRIVE - ONEVIRTUALOFFICE\\ETC\\GOPRO\\GOPRO\\lib\\site-packages\\PIL\\ImageFile.py:269\u001b[0m, in \u001b[0;36mImageFile.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    266\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(msg)\n\u001b[0;32m    268\u001b[0m b \u001b[39m=\u001b[39m b \u001b[39m+\u001b[39m s\n\u001b[1;32m--> 269\u001b[0m n, err_code \u001b[39m=\u001b[39m decoder\u001b[39m.\u001b[39;49mdecode(b)\n\u001b[0;32m    270\u001b[0m \u001b[39mif\u001b[39;00m n \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    271\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "_train(net, max_epoch = 1000, lr = 0.002, resume=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 81132,
     "status": "error",
     "timestamp": 1669619186175,
     "user": {
      "displayName": "서성종",
      "userId": "04139841364071843075"
     },
     "user_tz": -540
    },
    "id": "Azwsf98M1ikP",
    "outputId": "01413c80-e794-463d-c8ac-fc7b631c49c1"
   },
   "outputs": [],
   "source": [
    "_test(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOtwS2L7rMDyxgMyGe0kAUI",
   "mount_file_id": "19EkeB-LDexFbqOMbYd8agrQh2-OoCvOR",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "GOPRO",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (tags/v3.8.10:3d8993a, May  3 2021, 11:48:03) [MSC v.1928 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "d2cf4187e0bb1d27f0ec5a6746225fa23e96cfbadef5468ced2c57f6857522da"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
